# AuroraAI
# AuroraAI ðŸŒŒ

AuroraAI is an intelligent assistant inspired by the northern lights and the legends of Sleeping Beauty.  
The project aims to create a modular, expandable, and aesthetically elegant AI system with a focus on:

- ðŸ’¬ Natural language and dialogue
- ðŸ§  Memory and context
- ðŸ“Š Data processing
- ðŸ–¼ï¸ Visual capabilities (optional)



Project scaffold for AuroraAI.

Tree:

AuroraAI/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ aurora/                  # ÐžÑÐ½Ð¾Ð²Ð½Ð° Ð»Ð¾Ð³Ð¸ÐºÐ° Ð½Ð° AuroraAI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py              # Ð¯Ð´Ñ€Ð¾ Ð½Ð° Ð»Ð¾Ð³Ð¸ÐºÐ°Ñ‚Ð°
â”‚   â”œâ”€â”€ memory.py            # Ð”ÑŠÐ»Ð³Ð¾ÑÑ€Ð¾Ñ‡Ð½Ð° Ð¿Ð°Ð¼ÐµÑ‚ / ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
â”‚   â”œâ”€â”€ planner.py           # ÐœÐ¾Ð´ÑƒÐ» Ð·Ð° Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð°Ð½Ðµ Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸
â”‚   â”œâ”€â”€ nlp_tools.py         # Ð•Ð·Ð¸ÐºÐ¾Ð²Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸
â”‚   â””â”€â”€ vision.py            # ÐÐºÐ¾ Ñ‰Ðµ Ð¸Ð¼Ð° Ð²Ð¸Ð·ÑƒÐ°Ð»Ð½Ð¸ Ð²ÑŠÐ·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸
â”œâ”€â”€ models/                  # ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð¸ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
â”‚   â”œâ”€â”€ config/
â”‚   â””â”€â”€ checkpoints/
â”œâ”€â”€ data/                    # Ð”Ð°Ð½Ð½Ð¸, ÐºÐ¾Ð¸Ñ‚Ð¾ Aurora Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð²Ð°
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ scripts/                 # ÐŸÐ¾Ð¼Ð¾Ñ‰Ð½Ð¸ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ðµ
â”‚   â””â”€â”€ setup_env.sh
â”œâ”€â”€ tests/                   # Ð¢ÐµÑÑ‚Ð¾Ð²Ðµ
â”‚   â””â”€â”€ test_core.py
â””â”€â”€ notebooks/               # Jupyter ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¸
    â””â”€â”€ exploration.ipynb

Description
-----------
This repository is an minimal scaffold to start building AuroraAI: core logic, memory, planning, simple NLP/vision placeholders, and a basic test harness.

How to use
----------
1. Create a virtual environment and install dependencies:

```bash
bash scripts/setup_env.sh
```

2. Run the unit tests:

```bash
python -m unittest discover -v
```

3. Start implementing features under `aurora/`.


## Models
This repository separates code and model binaries. Model files (GGUF, PyTorch, Safetensors, checkpoints, etc.) are hosted on the Hugging Face Hub at:

https://huggingface.co/kenderov-emil4108/aurora-models

Do not commit model files, tokens, logs, or outputs to this Git repository. Model files are explicitly excluded via `.gitignore`.

To download the models into your local `models/` directory, run (from the project root):

```bash
export HF_TOKEN="$(cat secrets/hf_aurora.txt)"
python scripts/download_models.py --repo-id kenderov-emil4108/aurora-models --out models/
```

This script uses `huggingface_hub` to download all files stored in the `kenderov-emil4108/aurora-models` repo into the `models/` directory. Make sure your `secrets/hf_aurora.txt` contains a valid Hugging Face token with `read` access.

If you prefer to manually download models, visit the Hugging Face repo page linked above and use the web UI.

### Uploading models to Hugging Face (maintainers only)

Use the included upload script which streams files and shows progress per file:

```bash
export HF_TOKEN="$(cat secrets/hf_aurora.txt)"
python scripts/upload_models_to_hf.py --repo kenderov-emil4108/aurora-models --path models/
```

Notes:
- The script will attempt to create the HF repo if it does not exist. It will upload only model file extensions (`.gguf`, `.bin`, `.safetensors`, `.pt`, `.ckpt`).
- For very large (>2GB) files you may prefer to use the `huggingface-cli` or `git-lfs`.

### Security & best practices

- Never commit secrets or tokens. The `secrets/` directory is ignored by `.gitignore` and should remain local-only.
- When pushing code to GitHub, verify that `git status --porcelain` shows no secrets or models staged.
- If large files or tokens were accidentally committed in the past, follow the `git filter-repo` / BFG steps to purge them from history before pushing.
